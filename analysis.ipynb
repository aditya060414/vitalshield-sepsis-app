{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- This is the \"Bytes\" part ---\n",
    "\n",
    "# This is the full, correct path to the nested folder.\n",
    "file_path_to_patients = './mimic-iv-clinical-database-demo-2.2/mimic-iv-clinical-database-demo-2.2/hosp/patients.csv.gz' \n",
    "\n",
    "# Use pandas to read the gzipped CSV file\n",
    "try:\n",
    "    df_patients = pd.read_csv(file_path_to_patients)\n",
    "    \n",
    "    # Print the first 5 rows to see what it looks like\n",
    "    print(\"Successfully loaded patients.csv.gz:\")\n",
    "    print(df_patients.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find the file at {os.path.abspath(file_path_to_patients)}\")\n",
    "    print(\"Please double-check the folder and file name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- This is the \"Bytes\" part (Step 2) ---\n",
    "\n",
    "# Define the paths to the new files\n",
    "# (They are in the same 'hosp' folder as patients.csv.gz)\n",
    "base_path = './mimic-iv-clinical-database-demo-2.2/mimic-iv-clinical-database-demo-2.2/hosp/'\n",
    "file_path_diagnoses = os.path.join(base_path, 'diagnoses_icd.csv.gz')\n",
    "file_path_dictionary = os.path.join(base_path, 'd_icd_diagnoses.csv.gz')\n",
    "\n",
    "try:\n",
    "    # Load the diagnoses\n",
    "    df_diagnoses = pd.read_csv(file_path_diagnoses)\n",
    "    print(\"Successfully loaded diagnoses_icd.csv.gz:\")\n",
    "    print(df_diagnoses.head())\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\") # Adding a separator\n",
    "\n",
    "    # Load the dictionary\n",
    "    df_icd_dictionary = pd.read_csv(file_path_dictionary)\n",
    "    print(\"Successfully loaded d_icd_diagnoses.csv.gz:\")\n",
    "    print(df_icd_dictionary.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find one of the files.\")\n",
    "    print(f\"Looked for: {os.path.abspath(file_path_diagnoses)}\")\n",
    "    print(f\"And: {os.path.abspath(file_path_dictionary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- This is the \"Bytes\" part (Step 3) ---\n",
    "\n",
    "# We need to make sure the df_icd_dictionary is available from the previous cell\n",
    "# If you get an error, re-run the cell from Step 2 first.\n",
    "\n",
    "try:\n",
    "    # Search the 'long_title' column for any row containing 'Sepsis'\n",
    "    # 'case=False' makes the search case-insensitive\n",
    "    df_sepsis_codes = df_icd_dictionary[df_icd_dictionary['long_title'].str.contains('Sepsis', case=False, na=False)]\n",
    "\n",
    "    print(\"Found the following ICD codes for 'Sepsis':\")\n",
    "    print(df_sepsis_codes)\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: 'df_icd_dictionary' not found. Please re-run the previous cell (Step 2).\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e4b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- This is the \"Bytes\" part (Step 4) ---\n",
    "\n",
    "# We need the DataFrames from the previous steps\n",
    "# If you get an error, re-run the cells from Step 2 and 3 first.\n",
    "\n",
    "try:\n",
    "    # 1. Create a list of the sepsis ICD codes\n",
    "    sepsis_icd_code_list = df_sepsis_codes['icd_code'].tolist()\n",
    "    \n",
    "    print(f\"Searching for patients with these {len(sepsis_icd_code_list)} codes: {sepsis_icd_code_list}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # 2. Find all diagnoses that match any code in our list\n",
    "    df_sepsis_diagnoses = df_diagnoses[df_diagnoses['icd_code'].isin(sepsis_icd_code_list)]\n",
    "\n",
    "    # 3. Show the resulting patients\n",
    "    print(f\"Found {len(df_sepsis_diagnoses)} sepsis diagnoses in the demo set.\")\n",
    "    print(df_sepsis_diagnoses.head())\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: 'df_sepsis_codes' or 'df_diagnoses' not found. Please re-run the previous cells (Step 2 and 3).\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- This is the \"Bytes\" part (Step 5) ---\n",
    "\n",
    "# We need the df_sepsis_diagnoses from the previous step\n",
    "# If you get an error, re-run all previous cells.\n",
    "\n",
    "# Define the path to the ICU stays file\n",
    "base_path = './mimic-iv-clinical-database-demo-2.2/mimic-iv-clinical-database-demo-2.2/'\n",
    "file_path_icustays = os.path.join(base_path, 'icu/icustays.csv.gz')\n",
    "\n",
    "try:\n",
    "    # 1. Load the icustays file\n",
    "    df_icustays = pd.read_csv(file_path_icustays)\n",
    "    \n",
    "    # 2. Get a list of all unique hospital admissions in the ICU\n",
    "    all_icu_hadm_ids = set(df_icustays['hadm_id'].unique())\n",
    "    print(f\"Total unique hospital admissions in ICU: {len(all_icu_hadm_ids)}\")\n",
    "\n",
    "    # 3. Get a list of all unique hospital admissions with a sepsis diagnosis\n",
    "    sepsis_hadm_ids = set(df_sepsis_diagnoses['hadm_id'].unique())\n",
    "    print(f\"Total unique hospital admissions with Sepsis: {len(sepsis_hadm_ids)}\")\n",
    "\n",
    "    # 4. Create our \"Negative\" group\n",
    "    # These are admissions in the ICU that are NOT in our sepsis list\n",
    "    non_sepsis_hadm_ids = all_icu_hadm_ids - sepsis_hadm_ids\n",
    "    print(f\"Total unique hospital admissions without Sepsis: {len(non_sepsis_hadm_ids)}\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: 'df_sepsis_diagnoses' not found. Please re-run all previous cells first.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find icustays.csv.gz at {os.path.abspath(file_path_icustays)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- This is the \"Bytes\" part (Step 6) ---\n",
    "\n",
    "# We need 'all_icu_hadm_ids' from the previous step (Step 5)\n",
    "# If you get an error, re-run all previous cells.\n",
    "\n",
    "# Define the paths to the data files in their respective folders\n",
    "base_path_hosp = './mimic-iv-clinical-database-demo-2.2/mimic-iv-clinical-database-demo-2.2/hosp/'\n",
    "base_path_icu = './mimic-iv-clinical-database-demo-2.2/mimic-iv-clinical-database-demo-2.2/icu/'\n",
    "\n",
    "file_path_labs = os.path.join(base_path_hosp, 'labevents.csv.gz')\n",
    "file_path_vitals = os.path.join(base_path_icu, 'chartevents.csv.gz')\n",
    "\n",
    "try:\n",
    "    # 1. Load Lab Events and filter\n",
    "    print(f\"Loading {file_path_labs}...\")\n",
    "    df_labevents_all = pd.read_csv(file_path_labs)\n",
    "    print(f\"Loaded {len(df_labevents_all)} lab events.\")\n",
    "    \n",
    "    # Filter to only keep our 128 ICU patients\n",
    "    df_labevents = df_labevents_all[df_labevents_all['hadm_id'].isin(all_icu_hadm_ids)]\n",
    "    print(f\"Filtered lab events to {len(df_labevents)} rows (our ICU patients).\")\n",
    "    print(df_labevents.head())\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # 2. Load Chart Events (Vitals) and filter\n",
    "    print(f\"Loading {file_path_vitals}...\")\n",
    "    df_vitals_all = pd.read_csv(file_path_vitals)\n",
    "    print(f\"Loaded {len(df_vitals_all)} vital events.\")\n",
    "    \n",
    "    # Filter to only keep our 128 ICU patients\n",
    "    df_vitals = df_vitals_all[df_vitals_all['hadm_id'].isin(all_icu_hadm_ids)]\n",
    "    print(f\"Filtered vital events to {len(df_vitals)} rows (our ICU patients).\")\n",
    "    print(df_vitals.head())\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: 'all_icu_hadm_ids' not found. Please re-run all previous cells first (especially Step 5).\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find one of the files.\")\n",
    "    print(f\"Looked for: {os.path.abspath(file_path_labs)}\")\n",
    "    print(f\"And: {os.path.abspath(file_path_vitals)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22971f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- This is the \"Bytes\" part (Step 7) ---\n",
    "\n",
    "# Define the paths to the dictionary files\n",
    "base_path_hosp = './mimic-iv-clinical-database-demo-2.2/mimic-iv-clinical-database-demo-2.2/hosp/'\n",
    "base_path_icu = './mimic-iv-clinical-database-demo-2.2/mimic-iv-clinical-database-demo-2.2/icu/'\n",
    "\n",
    "file_path_lab_dict = os.path.join(base_path_hosp, 'd_labitems.csv.gz')\n",
    "file_path_vitals_dict = os.path.join(base_path_icu, 'd_items.csv.gz')\n",
    "\n",
    "try:\n",
    "    # 1. Load the Lab Items Dictionary\n",
    "    df_lab_dict = pd.read_csv(file_path_lab_dict)\n",
    "    print(\"Successfully loaded d_labitems.csv.gz:\")\n",
    "    print(df_lab_dict.head())\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # 2. Load the Chart/Vitals Items Dictionary\n",
    "    df_vitals_dict = pd.read_csv(file_path_vitals_dict)\n",
    "    print(\"Successfully loaded d_items.csv.gz:\")\n",
    "    print(df_vitals_dict.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find one of the dictionary files.\")\n",
    "    print(f\"Looked for: {os.path.abspath(file_path_lab_dict)}\")\n",
    "    print(f\"And: {os.path.abspath(file_path_vitals_dict)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- This is the \"Bytes\" part (Step 8) ---\n",
    "\n",
    "# We need df_lab_dict and df_vitals_dict from the previous step (Step 7)\n",
    "# If you get an error, re-run that cell first.\n",
    "\n",
    "try:\n",
    "    print(\"--- Finding Vitals itemids (from d_items.csv.gz) ---\")\n",
    "    \n",
    "    # Define the vitals we're looking for\n",
    "    vital_labels_to_find = [\n",
    "        'Heart Rate',\n",
    "        'Systolic', # For Systolic Blood Pressure\n",
    "        'Diastolic', # For Diastolic Blood Pressure\n",
    "        'Temperature',\n",
    "        'Respiratory Rate'\n",
    "    ]\n",
    "\n",
    "    # Create a search pattern (e.g., 'Heart Rate|Systolic|...')\n",
    "    vitals_search_pattern = '|'.join(vital_labels_to_find)\n",
    "    \n",
    "    # Search the 'label' column in the vitals dictionary\n",
    "    df_found_vitals = df_vitals_dict[df_vitals_dict['label'].str.contains(vitals_search_pattern, case=False, na=False)]\n",
    "    \n",
    "    print(\"Found the following vital sign itemids:\")\n",
    "    print(df_found_vitals[['itemid', 'label', 'category', 'unitname']])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"--- Finding Lab itemids (from d_labitems.csv.gz) ---\")\n",
    "    \n",
    "    # Define the labs we're looking for\n",
    "    lab_labels_to_find = [\n",
    "        'Lactate',\n",
    "        'White Blood Cell' # For WBC Count\n",
    "    ]\n",
    "\n",
    "    # Create a search pattern\n",
    "    labs_search_pattern = '|'.join(lab_labels_to_find)\n",
    "    \n",
    "    # Search the 'label' column in the lab dictionary\n",
    "    df_found_labs = df_lab_dict[df_lab_dict['label'].str.contains(labs_search_pattern, case=False, na=False)]\n",
    "    \n",
    "    print(\"Found the following lab itemids:\")\n",
    "    print(df_found_labs[['itemid', 'label', 'category', 'fluid']])\n",
    "\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: 'df_lab_dict' or 'df_vitals_dict' not found. Please re-run the previous cell (Step 7).\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- This is the \"Bytes\" part (Step 9) ---\n",
    "\n",
    "# We need df_lab_dict and df_vitals_dict from Step 7.\n",
    "# If you get an error, re-run that cell first.\n",
    "\n",
    "try:\n",
    "    # 1. Define the EXACT vitals labels we want\n",
    "    vital_labels_we_want = [\n",
    "        'Heart Rate',\n",
    "        'Non Invasive Blood Pressure systolic',\n",
    "        'Non Invasive Blood Pressure diastolic',\n",
    "        'Respiratory Rate',\n",
    "        'Temperature Fahrenheit', # We'll get F\n",
    "        'Temperature Celsius'   # and C, and normalize later\n",
    "    ]\n",
    "    \n",
    "    # 2. Define the EXACT lab labels we want\n",
    "    lab_labels_we_want = [\n",
    "        'Lactate',\n",
    "        'White Blood Cells'\n",
    "    ]\n",
    "    \n",
    "    # 3. Filter the dictionaries for ONLY these exact labels\n",
    "    df_vitals_final = df_vitals_dict[df_vitals_dict['label'].isin(vital_labels_we_want)]\n",
    "    df_labs_final = df_lab_dict[df_lab_dict['label'].isin(lab_labels_we_want)]\n",
    "    \n",
    "    print(\"--- Final Vitals 'Shopping List' ---\")\n",
    "    print(df_vitals_final[['itemid', 'label', 'category', 'unitname']])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\"--- Final Labs 'Shopping List' ---\")\n",
    "    print(df_labs_final[['itemid', 'label', 'category', 'fluid']])\n",
    "    \n",
    "    # 4. Store these IDs in a list for the next step\n",
    "    # These are the *only* itemids we care about from now on\n",
    "    vital_itemids_to_keep = df_vitals_final['itemid'].tolist()\n",
    "    lab_itemids_to_keep = df_labs_final['itemid'].tolist()\n",
    "    \n",
    "    print(f\"\\nVital ItemIDs to keep: {vital_itemids_to_keep}\")\n",
    "    print(f\"Lab ItemIDs to keep: {lab_itemids_to_keep}\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: 'df_lab_dict' or 'df_vitals_dict' not found. Please re-run the cell from Step 7.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8987d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- This is the \"Bytes\" part (Step 10) ---\n",
    "\n",
    "# We need all these from previous steps. Re-run steps 5, 6, and 9 if you get an error.\n",
    "try:\n",
    "    # 1. Filter the Vitals (df_vitals) using our vital_itemids_to_keep list\n",
    "    df_vitals_features = df_vitals[df_vitals['itemid'].isin(vital_itemids_to_keep)]\n",
    "    \n",
    "    print(\"--- Filtered Vitals Data ---\")\n",
    "    print(f\"Original vitals size (from Step 6): {len(df_vitals)} rows\")\n",
    "    print(f\"New filtered vitals size: {len(df_vitals_features)} rows\")\n",
    "    print(df_vitals_features.head())\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # 2. Filter the Labs (df_labevents) using our lab_itemids_to_keep list\n",
    "    df_lab_features = df_labevents[df_labevents['itemid'].isin(lab_itemids_to_keep)]\n",
    "\n",
    "    print(\"--- Filtered Labs Data ---\")\n",
    "    print(f\"Original labs size (from Step 6): {len(df_labevents)} rows\")\n",
    "    print(f\"New filtered labs size: {len(df_lab_features)} rows\")\n",
    "    print(df_lab_features.head())\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: One or more DataFrames (df_vitals, df_labevents) or lists (vital_itemids_to_keep, lab_itemids_to_keep) were not found.\")\n",
    "    print(\"Please re-run Step 5, Step 6, and Step 9 to define them.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a67579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- This is the \"Bytes\" part (Step 11) ---\n",
    "# This is Feature Engineering\n",
    "\n",
    "# We need:\n",
    "# df_icustays (from Step 5)\n",
    "# df_patients (from Step 1)\n",
    "# sepsis_hadm_ids (from Step 5)\n",
    "\n",
    "try:\n",
    "    # 1. Get one row per hospital admission (hadm_id)\n",
    "    # We use drop_duplicates to make sure we only have one entry per patient admission\n",
    "    df_icu_patients = df_icustays.drop_duplicates(subset=['hadm_id'], keep='first')\n",
    "\n",
    "    # 2. Merge with df_patients to add age and gender\n",
    "    # This creates our base feature matrix\n",
    "    df_feature_matrix = df_icu_patients.merge(df_patients, on='subject_id')\n",
    "    \n",
    "    # 3. Create the 'sepsis_label' (our target variable)\n",
    "    # .isin() checks if the hadm_id is in our 'sepsis_hadm_ids' set\n",
    "    # .astype(int) converts True/False to 1/0\n",
    "    df_feature_matrix['sepsis_label'] = df_feature_matrix['hadm_id'].isin(sepsis_hadm_ids).astype(int)\n",
    "\n",
    "    # 4. Clean up and show the result\n",
    "    # We only keep the columns we need\n",
    "    df_feature_matrix = df_feature_matrix[['subject_id', 'hadm_id', 'gender', 'anchor_age', 'sepsis_label']]\n",
    "    \n",
    "    print(\"--- Successfully Built Base Feature Matrix ---\")\n",
    "    print(df_feature_matrix.head())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    print(\"Checking our 1s and 0s (Sepsis vs. No Sepsis):\")\n",
    "    print(df_feature_matrix['sepsis_label'].value_counts())\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: One or more DataFrames (df_icustays, df_patients, sepsis_hadm_ids) were not found.\")\n",
    "    print(\"Please re-run Step 1, Step 5, and Step 9 to define them.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np # We'll need numpy for NaN\n",
    "\n",
    "# --- This is the \"Bytes\" part (Step 12) ---\n",
    "\n",
    "# We need all these from previous steps:\n",
    "# df_feature_matrix (Step 11)\n",
    "# df_vitals_features (Step 10)\n",
    "# df_lab_features (Step 10)\n",
    "# vital_itemids_to_keep, lab_itemids_to_keep (Step 9)\n",
    "\n",
    "try:\n",
    "    # 1. Unify Temperature (Convert C to F)\n",
    "    # Get a copy to avoid pandas warnings\n",
    "    df_vitals_processed = df_vitals_features.copy()\n",
    "    \n",
    "    # Find all Celsius rows (itemid 223762)\n",
    "    celsius_rows = df_vitals_processed['itemid'] == 223762\n",
    "    \n",
    "    # Convert C to F: (C * 9/5) + 32\n",
    "    df_vitals_processed.loc[celsius_rows, 'valuenum'] = (df_vitals_processed.loc[celsius_rows, 'valuenum'] * 9/5) + 32\n",
    "    \n",
    "    \n",
    "    # 2. Map ItemIDs to Names\n",
    "    vital_id_to_name_map = {\n",
    "        220210: 'RESP_RATE',\n",
    "        220180: 'BP_DIASTOLIC',\n",
    "        223761: 'TEMP_F',        # Already in F\n",
    "        223762: 'TEMP_F',        # Now converted to F\n",
    "        220045: 'HEART_RATE',\n",
    "        220179: 'BP_SYSTOLIC'\n",
    "    }\n",
    "    \n",
    "    # Get all the lactate and WBC itemids from our list in Step 9\n",
    "    lab_id_to_name_map = {}\n",
    "    for itemid in lab_itemids_to_keep:\n",
    "        if itemid in [50813, 52442]:\n",
    "            lab_id_to_name_map[itemid] = 'LACTATE'\n",
    "        else:\n",
    "            lab_id_to_name_map[itemid] = 'WBC' # All others are WBC\n",
    "            \n",
    "    # Apply the mapping\n",
    "    df_vitals_processed['feature_name'] = df_vitals_processed['itemid'].map(vital_id_to_name_map)\n",
    "    \n",
    "    df_labs_processed = df_lab_features.copy()\n",
    "    df_labs_processed['feature_name'] = df_labs_processed['itemid'].map(lab_id_to_name_map)\n",
    "\n",
    "    \n",
    "    # 3. Aggregate (Get Max Value)\n",
    "    # We group by patient (hadm_id) and feature, get the max value, then 'unstack'\n",
    "    # .unstack() pivots the feature_name from a row into columns\n",
    "    df_vitals_agg = df_vitals_processed.groupby(['hadm_id', 'feature_name'])['valuenum'].max().unstack()\n",
    "    df_labs_agg = df_labs_processed.groupby(['hadm_id', 'feature_name'])['valuenum'].max().unstack()\n",
    "    \n",
    "    # Rename columns (e.g., 'HEART_RATE' -> 'HEART_RATE_max')\n",
    "    df_vitals_agg = df_vitals_agg.add_suffix('_max')\n",
    "    df_labs_agg = df_labs_agg.add_suffix('_max')\n",
    "    \n",
    "\n",
    "    # 4. Merge all features into our base table\n",
    "    df_final_features = df_feature_matrix.merge(df_vitals_agg, on='hadm_id', how='left')\n",
    "    df_final_features = df_final_features.merge(df_labs_agg, on='hadm_id', how='left')\n",
    "    \n",
    "    print(\"--- Successfully Built FINAL Feature Matrix ---\")\n",
    "    print(df_final_features.head())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    print(\"Checking for missing values (NaN):\")\n",
    "    # .isnull() finds missing values, .sum() counts them\n",
    "    print(df_final_features.isnull().sum())\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Error: A required DataFrame or list was not found. {e}\")\n",
    "    print(\"Please re-run all steps from Step 9, 10, and 11.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- This is the \"Bytes\" part (Step 13) ---\n",
    "# This is Data Pre-processing\n",
    "\n",
    "# We need df_final_features from the previous step (Step 12)\n",
    "try:\n",
    "    # 1. Calculate the median for LACTATE_max\n",
    "    # We use 'skipna=True' (the default) to ignore the NaNs when calculating\n",
    "    median_lactate = df_final_features['LACTATE_max'].median()\n",
    "    \n",
    "    print(f\"Calculated median for LACTATE_max: {median_lactate}\")\n",
    "    \n",
    "    # 2. Fill the missing values\n",
    "    # We use 'inplace=True' to modify the table directly\n",
    "    df_final_features['LACTATE_max'].fillna(median_lactate, inplace=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    print(\"Checking for missing values after imputation:\")\n",
    "    print(df_final_features.isnull().sum())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    print(\"--- Final, Cleaned, AI-Ready Dataset ---\")\n",
    "    print(df_final_features.head())\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: 'df_final_features' not found.\")\n",
    "    print(\"Please re-run all steps from Step 12.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- This is the \"AI\" part (Step 14) ---\n",
    "\n",
    "# We need df_final_features from the previous step (Step 13)\n",
    "try:\n",
    "    # 1. Prepare for AI (Convert 'gender' to 0s and 1s)\n",
    "    # This creates new columns: 'gender_F' and 'gender_M'\n",
    "    df_model_data = pd.get_dummies(df_final_features, columns=['gender'], drop_first=True)\n",
    "    \n",
    "    # 2. Define Features (X) and Target (y)\n",
    "    # X = All columns EXCEPT the answer ('sepsis_label') and patient IDs\n",
    "    X = df_model_data.drop(columns=['subject_id', 'hadm_id', 'sepsis_label'])\n",
    "    \n",
    "    # y = ONLY the answer column\n",
    "    y = df_model_data['sepsis_label']\n",
    "    \n",
    "    # 3. Split Data\n",
    "    # test_size=0.2 means 20% for testing, 80% for training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Total patients: {len(X)}\")\n",
    "    print(f\"Training patients: {len(X_train)}\")\n",
    "    print(f\"Testing patients: {len(X_test)}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # 4. Create and Train the Model\n",
    "    # We create an instance of the LogisticRegression model\n",
    "    model = LogisticRegression(max_iter=1000) # max_iter=1000 helps it solve\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"--- Model Trained Successfully! ---\")\n",
    "    \n",
    "    # 5. Evaluate the Model\n",
    "    # Make predictions on the \"unseen\" test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Check the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    print(f\"MODEL ACCURACY ON TEST DATA: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: 'df_final_features' not found.\")\n",
    "    print(\"Please re-run all steps from Step 12 & 13.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd2badcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Saved Successfully! ---\n",
      "Model saved to: sepsis_model.pkl\n",
      "Columns saved to: model_columns.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# --- This is the \"Bytes\" part (Step 15) ---\n",
    "# Saving our model to a file\n",
    "\n",
    "# We need the 'model' variable from Step 14\n",
    "try:\n",
    "    # Save the model to a file named 'sepsis_model.pkl'\n",
    "    joblib.dump(model, 'sepsis_model.pkl')\n",
    "    \n",
    "    # Save the list of feature columns\n",
    "    # We need this so our app knows the correct order and names\n",
    "    feature_columns = X_train.columns\n",
    "    joblib.dump(feature_columns, 'model_columns.pkl')\n",
    "    \n",
    "    print(\"--- Model Saved Successfully! ---\")\n",
    "    print(f\"Model saved to: sepsis_model.pkl\")\n",
    "    print(f\"Columns saved to: model_columns.pkl\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"Error: 'model' or 'X_train' not found.\")\n",
    "    print(\"Please re-run Step 14 to train the model and define X_train.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
